# -*- coding: utf-8 -*-
"""FinalAQIPredictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SpoA1tOz23mCvdBvHWQagJZY0M31JIkP
"""


import os
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY")
HOPSWORKS_API_KEY = os.getenv("HOPSWORKS_API_KEY")
    
import requests, time, datetime as dt
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import os
import gradio as gr
import hopsworks
import joblib
from datetime import datetime, timedelta, UTC
from meteostat import Point, Hourly
from tqdm import tqdm
plt.style.use('fivethirtyeight')

MODEL_PATH = "final_lgbm_multioutput.pkl"
SCALER_PATH = "scaler.pkl"
PT_X_PATH = "feature_power_transformer.pkl"
PT_Y_PATH = "target_power_transformer.pkl"

def get_aqi_us(components):
    # Pollutant concentration breakpoints (in Œºg/m¬≥) from the openweather table
    POLLUTANT_CONCENTRATIONS = {
        'co': [(0, 4400), (4401, 9400), (9401, 12400), (12401, 15400), (15401, 30400), (30401, 40400), (40401, 50400)],
        'no2': [(0, 100), (101, 200), (201, 700), (701, 1200), (1201, 2340), (2341, 3090), (3091, 4048)],
        'o3': [(0, 106), (107, 138), (139, 168), (169, 208), (209, 748)],
        'so2': [(0, 88), (89, 200), (201, 786), (787, 1572), (1573, 2100)],
        'pm2_5': [(0, 12.0), (12.1, 35.4), (35.5, 55.4), (55.5, 150.4), (150.5, 250.4), (250.5, 350.4), (350.5, 500.4)],
        'pm10': [(0, 54), (55, 154), (155, 254), (255, 354), (355, 424), (425, 504), (505, 604)]
    }

    # Corresponding AQI levels from the table
    AQI_LEVELS = [(0, 50), (51, 100), (101, 150), (151, 200), (201, 300), (301, 400), (401, 500)]

    def get_pollutant_aqi(concentration, pollutant):
        if concentration is None or np.isnan(concentration) or pollutant not in POLLUTANT_CONCENTRATIONS:
            return None

        for i, (conc_low, conc_high) in enumerate(POLLUTANT_CONCENTRATIONS[pollutant]):
            if conc_low <= concentration <= conc_high:
                aqi_low, aqi_high = AQI_LEVELS[i]
                try:
                    aqi = ((aqi_high - aqi_low) / (conc_high - conc_low)) * (concentration - conc_low) + aqi_low
                    return round(aqi)
                except ZeroDivisionError:
                    return aqi_low

        max_range = POLLUTANT_CONCENTRATIONS[pollutant]
        if max_range and concentration > max_range[-1][1]:
            return AQI_LEVELS[-1][1]

        return None
    sub_indices = [
        get_pollutant_aqi(components.get('co'), 'co'),
        get_pollutant_aqi(components.get('no2'), 'no2'),
        get_pollutant_aqi(components.get('o3'), 'o3'),
        get_pollutant_aqi(components.get('so2'), 'so2'),
        get_pollutant_aqi(components.get('pm2_5'), 'pm2_5'),
        get_pollutant_aqi(components.get('pm10'), 'pm10')
    ]

    valid_indices = [idx for idx in sub_indices if idx is not None]

    if not valid_indices:
        return np.nan

    return max(valid_indices)

def get_aqi_category(aqi):
    if aqi <= 50: return "Good", "green"
    elif aqi <= 100: return "Moderate", "yellow"
    elif aqi <= 150: return "Unhealthy for Sensitive Groups", "orange"
    elif aqi <= 200: return "Unhealthy", "red"
    elif aqi <= 300: return "Very Unhealthy", "purple"
    else: return "Hazardous", "maroon"

BASE_URL = "http://api.openweathermap.org/data/2.5/air_pollution"
#Backfilling
end = int(time.time())
start = end - (1000*24*3600)

def fetch_aqi_history_data(lat,lon,start=start, end=end, api_key=OPENWEATHER_API_KEY):
    url = f"{BASE_URL}/history?lat={lat}&lon={lon}&start={start}&end={end}&appid={api_key}"
    resp = requests.get(url)
    resp.raise_for_status()
    data = resp.json()["list"]

    records = []
    for entry in data:
        ts = pd.to_datetime(entry["dt"], unit="s")
        aqi = entry["main"]["aqi"]
        comps = entry["components"]
        records.append({"timestamp": ts, "aqi": aqi, **comps})
    return pd.DataFrame(records)

def fetch_weather_data(lat, lon, start=start, end=end):
    print("\nFetching weather data from Meteostat...")
    start_dt = datetime.fromtimestamp(start, UTC)
    end_dt = datetime.fromtimestamp(end, UTC)

    start_dt = start_dt.replace(tzinfo=None)
    end_dt = end_dt.replace(tzinfo=None)

    location = Point(lat, lon)
    data = Hourly(location, start_dt, end_dt)
    df_weather = data.fetch()
    drop = ['dwpt', 'snow', 'wpgt', 'tsun', 'coco', 'wdir','prcp']
    df_weather = df_weather.drop(columns=drop)
    df_weather = df_weather.reset_index().rename(columns={'time': 'timestamp'})
    df_weather = df_weather.sort_values("timestamp").reset_index(drop=True)
    print(f"Weather Data fetched: {len(df_weather)} rows")
    return df_weather

def fetch_lat_lon(city_name, api_key=OPENWEATHER_API_KEY):
  resp = requests.get(f"http://api.openweathermap.org/geo/1.0/direct?q={city_name}&limit=5&appid={api_key}")
  if resp.status_code != 200:
        raise Exception(f"API Error: {resp.text}")
  lat = resp.json()[0]["lat"]
  lon = resp.json()[0]["lon"]
  return lat,lon
     
def merge_and_preprocess(df_aqi, df_weather):
    merged = pd.merge_asof(
        df_aqi.sort_values("timestamp"),
        df_weather.sort_values("timestamp"),
        on="timestamp",
        direction="nearest",
        tolerance=pd.Timedelta("1h")
    )
    # Drop duplicate timestamps if any
    merged = merged.drop_duplicates(subset='timestamp')

    # Forward-fill short weather gaps within same day
    merged['date'] = merged['timestamp'].dt.date
    cols_to_fill = ['temp', 'rhum', 'wspd', 'pres']
    merged[cols_to_fill] = merged.groupby('date')[cols_to_fill].ffill(limit=3)
    merged.drop(columns=['date'], inplace=True)

    merged['us_aqi'] = merged.apply(get_aqi_us, axis=1)
    merged = merged.dropna()

    return merged

def create_features(df):
    df = df.copy()
    df['hour'] = df.index.hour
    df['month'] = df.index.month
    df['dayofweek'] = df.index.dayofweek
    df['dayofmonth'] = df.index.day
    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)

    df['sin_dayofweek'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
    df['cos_dayofweek'] = np.cos(2 * np.pi * df['dayofweek'] / 7)

    df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)
    df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)
    return df

def add_lags(df, col="aqi"):
    df['onedaylag'] = df['us_aqi'].shift(24)
    df['twodaylag'] = df['us_aqi'].shift(48)
    df['threedaylag'] = df['us_aqi'].shift(72)
    df["aqi_roll_std_3"] = df["us_aqi"].rolling(72).std().shift(24)
    df["us_aqi_roll_mean_3d"] = df["us_aqi"].rolling(72).mean().shift(24)
    df["pm2_5_rhum"] = df["pm2_5"] * df["rhum"]  # humidity amplifies PM2.5 concentration
    df["no2_temp"] = df["no2"] * df["temp"]      # hot weather increases NO2 dispersion/reaction
    return df

def save_to_feature_store(df,name,description,vers,api_key=HOPSWORKS_API_KEY):
    project = hopsworks.login(api_key_value=api_key)
    fs = project.get_feature_store()
    fg = fs.get_or_create_feature_group(
        name=name,
        version=vers,
        primary_key=["timestamp"],
        description=description
    )
    fg.insert(df, write_options={"wait_for_job": True})
    print("Saved features to Hopsworks Feature Store")

def load_from_feature_store(name="aqi_feature", version=1):
    project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)
    fs = project.get_feature_store()
    fg = fs.get_feature_group(name, version=version)
    if fg:
        df = fg.read()
        df = df.set_index('timestamp')
        df.index = pd.to_datetime(df.index)
        df = df.sort_index()
        return df  
    else:
        print("No DataFrame Fetched!")
        return pd.DataFrame()


def run_feature_pipeline():
    print("Running Feature Pipeline...")
    lat, lon = fetch_lat_lon("Karachi", OPENWEATHER_API_KEY)
    print(f"Fetched coordinates: {lat}, {lon}")

    df_aqi = fetch_aqi_history_data(lat,lon)
    df_weather = fetch_weather_data(lat,lon)
    df_aqi = df_aqi.sort_values("timestamp")
    df_weather = df_weather.sort_values("timestamp")
    df_aqi.replace(-9999, np.nan, inplace=True)
    df_weather.replace(-9999, np.nan, inplace=True)

    df = merge_and_preprocess(df_aqi, df_weather)
    df['us_aqi'] = df.apply(get_aqi_us, axis=1)
    df = df.drop(columns=['aqi'])
    df = df.set_index('timestamp')
    df.index = pd.to_datetime(df.index)
    df = df.resample("1H").asfreq()
    df.to_csv("history_aqi.csv", index=False, encoding="utf-8")
    print(f"Saved data to history_aqi.csv")

    df = create_features(df)
    df = add_lags(df)
    features_to_drop = ['co', 'nh3','no','o3','hour', 'dayofweek', 'month']
    df=df.drop(columns=features_to_drop)
    df=df.dropna()
    df = df.reset_index()
    save_to_feature_store(df,"aqi_feature","Features for AQI prediction",1,HOPSWORKS_API_KEY)
    print("Feature pipeline completed.")

def create_targets_full(df):
  df['aqi_24'] = df['us_aqi'].rolling(window=24).mean().shift(-24)
  df['aqi_48'] = df['us_aqi'].rolling(window=48).mean().shift(-48)
  df['aqi_72'] = df['us_aqi'].rolling(window=72).mean().shift(-72)
  return df

def run_training_pipeline():
    from sklearn.multioutput import MultiOutputRegressor
    from sklearn.preprocessing import StandardScaler, PowerTransformer
    from sklearn.metrics import (
        mean_squared_error, mean_absolute_error, r2_score, make_scorer
    )
    import lightgbm as lgb

    df = load_from_feature_store()
    df = df.sort_index()
    df = create_targets_full(df)
    df = df.dropna()

    features = [
                'pm2_5', 'pm10', 'no2', 'so2',
                'onedaylag', 'twodaylag', 'threedaylag',
                'aqi_roll_std_3', 'us_aqi_roll_mean_3d',
                'pm2_5_rhum', 'no2_temp',
                'temp', 'rhum', 'pres', 'wspd',
                'sin_hour', 'cos_hour',
                'sin_dayofweek', 'cos_dayofweek',
                'sin_month', 'cos_month',
    ]
    targets = ['aqi_24','aqi_48','aqi_72']

    X = df[features]
    y = df[targets]

    cols_to_transform = ['pm2_5','pm10','no2','so2','onedaylag','twodaylag','threedaylag']

    pt_X = PowerTransformer(method='yeo-johnson', standardize=False)
    X_tf = X.copy()
    X_tf[cols_to_transform] = pt_X.fit_transform(X_tf[cols_to_transform])

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_tf)
    X_scaled = pd.DataFrame(X_scaled, columns=features, index=X.index)

    pt_y = PowerTransformer(method='yeo-johnson')
    y_tf = pt_y.fit_transform(y)

    # --- Model ---
    base_model = lgb.LGBMRegressor(
        n_estimators=2000,
        learning_rate=0.01,
        num_leaves=64,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_alpha=0.2,
        reg_lambda=0.2,
        min_child_samples=30,
        random_state=42,
        n_jobs=-1
    )

    final_model = MultiOutputRegressor(base_model)
    final_model.fit(X_scaled, y_tf)
    print("Final MultiOutput model trained on all data")

    y_pred_tf = final_model.predict(X_scaled)
    y_pred = pt_y.inverse_transform(y_pred_tf)

    for i, col in enumerate(targets):
        rmse = np.sqrt(mean_squared_error(y.iloc[:, i], y_pred[:, i]))
        mae = mean_absolute_error(y.iloc[:, i], y_pred[:, i])
        r2 = r2_score(y.iloc[:, i], y_pred[:, i])
        print(f"{col} ‚Üí RMSE={rmse:.3f}, MAE={mae:.3f}, R¬≤={r2:.3f}")

    # --- Save ---
    joblib.dump(final_model, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    joblib.dump(pt_X, PT_X_PATH)
    joblib.dump(pt_y, PT_Y_PATH)
    print("Model + transformers saved.")

def run_dashboard():
    from PIL import Image
    model = joblib.load("final_lgbm_multioutput.pkl")
    scaler = joblib.load("scaler.pkl")
    pt_X = joblib.load("feature_power_transformer.pkl")
    pt_y = joblib.load("target_power_transformer.pkl")

    from PIL import Image

    def fig_to_image(fig):
        buf = io.BytesIO()
        fig.savefig(buf, format="png", bbox_inches="tight")
        buf.seek(0)
        img = Image.open(buf)
        plt.close(fig)
        return img

    def predict_aqi_dashboard():
        city_name = "Karachi"
        try:
            fs = project.get_feature_store()
            fg = fs.get_feature_group("aqi_feature", version=1)
            df = fg.read()
            df = df.set_index('timestamp')
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()
        except Exception as e:
            return f"<b style='color:#FF6B6B'>Error fetching from Feature Store: {e}</b>", None, None, None

        features = [
                'pm2_5', 'pm10', 'no2', 'so2',
                'onedaylag', 'twodaylag', 'threedaylag',
                'aqi_roll_std_3', 'us_aqi_roll_mean_3d',
                'pm2_5_rhum', 'no2_temp',
                'temp', 'rhum', 'pres', 'wspd',
                'sin_hour', 'cos_hour',
                'sin_dayofweek', 'cos_dayofweek',
                'sin_month', 'cos_month',
        ]
        cols_to_transform = ['pm2_5','pm10','no2','so2','onedaylag','twodaylag','threedaylag']

        X = df[features].tail(1)
        X_tf = X.copy()
        X_tf[cols_to_transform] = pt_X.transform(X_tf[cols_to_transform])
        X_scaled = scaler.transform(X_tf)
        X_scaled = pd.DataFrame(X_scaled, columns=X_tf.columns)
        y_pred_tf = model.predict(X_scaled)
        y_pred = pt_y.inverse_transform(y_pred_tf)
        preds = {"24h": y_pred[0,0], "48h": y_pred[0,1], "72h": y_pred[0,2]}

        # Forecast Plot
        df_preds = pd.DataFrame({
            "Hours Ahead": [24, 48, 72],
            "Predicted AQI": [preds["24h"], preds["48h"], preds["72h"]],
        })
        plt.style.use("dark_background")
        fig1, ax1 = plt.subplots(figsize=(6,4), facecolor="#0B132B")
        ax1.plot(df_preds["Hours Ahead"], df_preds["Predicted AQI"], marker="o", color="#00B4D8", linewidth=2.5)
        ax1.set_title(f"AQI Forecast for {city_name.title()}", fontsize=14, fontweight='bold', color="#F1F1F1")
        ax1.set_xlabel("Hours Ahead", fontsize=11, color="#B0BEC5")
        ax1.set_ylabel("Predicted AQI", fontsize=11, color="#B0BEC5")
        img1 = fig_to_image(fig1)

        # Recent Trend Plot
        df_recent = df.tail(48)
        fig2, ax2 = plt.subplots(figsize=(6,4), facecolor="#0B132B")
        ax2.plot(df_recent.index, df_recent["us_aqi"], color="#FFD166", linewidth=2)
        ax2.set_title("Recent AQI Trend (Past 48h)", fontsize=13, fontweight='bold', color="#F1F1F1")
        ax2.set_xlabel("Time", fontsize=11, color="#B0BEC5")
        ax2.set_ylabel("AQI", fontsize=11, color="#B0BEC5")
        plt.xticks(rotation=30)
        img2 = fig_to_image(fig2)

        # AQI Card
        cat, color = get_aqi_category(preds["24h"])
        status_html = f"""
        <div style='padding: 25px; border-radius: 15px; background:{color}; color:#0B132B; text-align:center; font-family:Inter, sans-serif'>
            <h2 style='margin:0;'>üå´Ô∏è Current AQI Category</h2>
            <h1 style='margin:5px 0; font-size:42px; font-weight:800'>{cat}</h1>
            <h3>Predicted AQI (Next 24h): {preds["24h"]:.1f}</h3>
        </div>
        """

        return status_html, img1, img2, df_preds

    # === Custom CSS ===
    css = """
    .gradio-container {
        background: linear-gradient(145deg, #0B132B, #1C2541);
        color: #E0E0E0;
        font-family: 'Inter', sans-serif;
    }
    label, h1, h2, h3, p, .gr-button {
        color: #E0E0E0 !important;
    }
    button {
        background-color: #5A4FCF !important;
        border: none !important;
        font-weight: 600 !important;
        border-radius: 12px !important;
        transition: 0.2s ease-in-out;
    }
    button:hover {
        background-color: #7369F5 !important;
        transform: scale(1.03);
    }
    input {
        background-color: #1C2541 !important;
        border: 1px solid #3A506B !important;
        color: #F1F1F1 !important;
        border-radius: 10px !important;
    }
    .gr-box, .gr-panel, .gr-compact {
        background-color: #1C2541 !important;
        border-radius: 15px !important;
        border: 1px solid #3A506B !important;
    }

    /* --- Dataframe styling --- */
    .dataframe {
        background-color: #0E1628 !important;
        border-radius: 10px !important;
        border: 1px solid #263E5A !important;
        color: #E0E0E0 !important;
    }
    .dataframe td, .dataframe th {
        border: none !important;
        text-align: center !important;
        font-size: 15px !important;
        font-weight: 600 !important;
        padding: 12px 16px !important;
        background-color: #1A2238 !important;
        color: #E8E8FF !important;
    }
    .dataframe th {
        background-color: #27355B !important;
        color: #BFC8F8 !important;
    }
    .dataframe td {
        border-radius: 8px !important;
    }
    .dataframe td input {
        width: 160px !important;  /* wider columns */
        height: 38px !important;  /* more rectangular height */
        border-radius: 6px !important; /* subtle rounding */
        background-color: #4C47C0 !important;
        color: white !important;
        font-weight: 600 !important;
        text-align: center !important;
    }

    /* Remove excess space */
    .gr-row {
        margin-top: 12px !important;
        margin-bottom: 12px !important;
    }

    footer {display: none !important;}
    """

    # === Gradio App ===
    with gr.Blocks(css=css, theme="gradio/soft") as app:
        gr.HTML("""
        <div style='background:#1F2A47; color:white; padding:25px; border-radius:15px; text-align:center;'>
            <h1 style='margin:0; font-size:34px; letter-spacing:0.5px;'>üåç Karachi Pearls AQI Predictor Dashboard</h1>
            <p style='margin:5px 0 0 0; font-size:16px; color:#D1D5DB;'>Monitor and forecast Air Quality Index trends using Machine Learning and real-time Hopsworks data.</p>
        </div>
        """)
        with gr.Row(equal_height=True):
          run_button = gr.Button("üîÆ Predict AQI for Karachi", variant="primary")

        with gr.Row():
            aqi_card = gr.HTML(label="üå´Ô∏è AQI Category")

        with gr.Row(equal_height=True):
            with gr.Column(scale=1):
                forecast_img = gr.Image(label="üìä AQI Forecast (Next 3 Days)")
            with gr.Column(scale=1):
                trend_img = gr.Image(label="üïí Recent AQI Trend (Past 48h)")

        with gr.Row():
            df_output = gr.Dataframe(label="üìÖ Predicted AQI Levels", wrap=True)

        run_button.click(
            predict_aqi_dashboard,
            inputs=[],
            outputs=[aqi_card, forecast_img, trend_img, df_output]
        )

    app.launch(debug=True)

import sys
if __name__ == "__main__":
    if "--task" in sys.argv:
        task = sys.argv[sys.argv.index("--task") + 1]
        if task == "feature":
            run_feature_pipeline()
        elif task == "train":
            run_training_pipeline()
        elif task == "dashboard":
            run_dashboard()
        else:
            print("Unknown task. Use --task feature/train/dashboard")
    else:
        print("‚ÑπPlease specify a task. Example: python pearlsaqipredictor.py --task train")

#!mkdir -p .github/workflows

# Commented out IPython magic to ensure Python compatibility.
# %%writefile .github/workflows/feature_pipeline.yml
# # .github/workflows/feature_pipeline.yml
# name: Hourly Feature Pipeline
# 
# on:
#   schedule:
#     - cron: "0 * * * *"   # every hour
#   workflow_dispatch:      # allow manual trigger
# 
# jobs:
#   feature_job:
#     runs-on: ubuntu-latest
#     steps:
#       - uses: actions/checkout@v4
#       - uses: actions/setup-python@v5
#         with:
#           python-version: '3.12'
#       - run: pip install -r requirements.txt
#       - name: Run feature pipeline
#         env:
#           OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
#           HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
#         run: python pearlsaqipredictor.py --task feature

# Commented out IPython magic to ensure Python compatibility.
# %%writefile .github/workflows/training_pipeline.yml
# # .github/workflows/train_pipeline.yml
# name: Daily Training Pipeline
# 
# on:
#   schedule:
#     - cron: "0 0 * * *"  # midnight UTC
#   workflow_dispatch:
# 
# jobs:
#   train_job:
#     runs-on: ubuntu-latest
#     steps:
#       - uses: actions/checkout@v4
#       - uses: actions/setup-python@v5
#         with:
#           python-version: '3.12'
#       - run: pip install -r requirements.txt
#       - name: Run training pipeline
#         env:
#           HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
#         run: python pearlsaqipredictor.py --task train
